{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927068e2",
   "metadata": {},
   "source": [
    "Construction of the RatPup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00733d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Duration Statistics (seconds) ===\n",
      "Mean: 0.1066\n",
      "Median: 0.1020\n",
      "Std Dev: 0.0666\n",
      "Q1: 0.0517, Q3: 0.1532, IQR: 0.1015\n",
      "\n",
      "=== Outlier Thresholds ===\n",
      "Lower fence (Q1 - 1.5·IQR): -0.1005 sec\n",
      "Upper fence (Q3 + 1.5·IQR): 0.3055 sec\n",
      "\n",
      "=== Outliers Detected ===\n",
      "Number of outlier events: 12\n",
      "Minimum outlier duration: 0.3060 sec\n",
      "Maximum outlier duration: 0.5000 sec\n",
      "\n",
      "List of outlier durations (first 20 shown):\n",
      "0.306\n",
      "0.311\n",
      "0.319\n",
      "0.332\n",
      "0.342\n",
      "0.343\n",
      "0.347\n",
      "0.368\n",
      "0.388\n",
      "0.433\n",
      "0.460\n",
      "0.500\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Function to parse a time string \"M:SS.mmm\" or \"H:MM:SS.mmm\" into seconds (float)\n",
    "def parse_time_to_seconds(time_str: str) -> float:\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        hours = float(parts[0])\n",
    "        minutes = float(parts[1])\n",
    "        seconds = float(parts[2])\n",
    "    elif len(parts) == 2:\n",
    "        hours = 0.0\n",
    "        minutes = float(parts[0])\n",
    "        seconds = float(parts[1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "# 3. Collect all durations, track empty files\n",
    "root_dir = 'XXXX'\n",
    "csv_pattern = os.path.join(root_dir, '**', '*.csv')\n",
    "csv_files = glob.glob(csv_pattern, recursive=True)\n",
    "\n",
    "all_durations = []\n",
    "empty_files = []\n",
    "skipped = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        # split on comma or tab\n",
    "        df = pd.read_csv(csv_file, sep=r'[,\\t]+', engine='python', dtype=str)\n",
    "    except Exception as e:\n",
    "        skipped.append((csv_file, f'read error: {e}'))\n",
    "        continue\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    if 'Duration' not in df.columns:\n",
    "        skipped.append((csv_file, f\"no 'Duration' column; got {df.columns.tolist()}\"))\n",
    "        continue\n",
    "\n",
    "    # drop rows where Duration is NaN or empty\n",
    "    df = df.dropna(subset=['Duration'])\n",
    "    df = df[df['Duration'].str.strip() != '']\n",
    "\n",
    "    # if no data left, record as empty\n",
    "    if df.empty:\n",
    "        empty_files.append(csv_file)\n",
    "        continue\n",
    "\n",
    "    # parse durations\n",
    "    try:\n",
    "        durations = df['Duration'].apply(parse_time_to_seconds)\n",
    "        all_durations.extend(durations.tolist())\n",
    "    except Exception as e:\n",
    "        skipped.append((csv_file, f'parse error: {e}'))\n",
    "        continue\n",
    "\n",
    "# 4. Report skipped and empty files\n",
    "if skipped:\n",
    "    print(\"\\nSkipped files:\")\n",
    "    for fname, reason in skipped:\n",
    "        print(f\"  - {fname}: {reason}\")\n",
    "\n",
    "# 5. Compute statistics if any durations collected\n",
    "if not all_durations:\n",
    "    print(\"\\nNo valid Duration data found. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "dur_series = pd.Series(all_durations, name='duration_sec')\n",
    "mean = dur_series.mean()\n",
    "median = dur_series.median()\n",
    "std = dur_series.std()\n",
    "q1 = dur_series.quantile(0.25)\n",
    "q3 = dur_series.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# 6. Define outlier thresholds using the IQR method\n",
    "lower_fence = q1 - 1.5 * iqr\n",
    "upper_fence = q3 + 1.5 * iqr\n",
    "\n",
    "# 7. Identify outliers\n",
    "outliers = dur_series[(dur_series < lower_fence) | (dur_series > upper_fence)]\n",
    "\n",
    "# 8. Print results\n",
    "print(\"\\n=== Duration Statistics (seconds) ===\")\n",
    "print(f\"Mean: {mean:.4f}\")\n",
    "print(f\"Median: {median:.4f}\")\n",
    "print(f\"Std Dev: {std:.4f}\")\n",
    "print(f\"Q1: {q1:.4f}, Q3: {q3:.4f}, IQR: {iqr:.4f}\")\n",
    "\n",
    "print(\"\\n=== Outlier Thresholds ===\")\n",
    "print(f\"Lower fence (Q1 - 1.5·IQR): {lower_fence:.4f} sec\")\n",
    "print(f\"Upper fence (Q3 + 1.5·IQR): {upper_fence:.4f} sec\")\n",
    "\n",
    "print(\"\\n=== Outliers Detected ===\")\n",
    "print(f\"Number of outlier events: {len(outliers)}\")\n",
    "if not outliers.empty:\n",
    "    print(f\"Minimum outlier duration: {outliers.min():.4f} sec\")\n",
    "    print(f\"Maximum outlier duration: {outliers.max():.4f} sec\")\n",
    "    print(\"\\nList of outlier durations (first 20 shown):\")\n",
    "    print(outliers.sort_values().head(20).to_string(index=False))\n",
    "else:\n",
    "    print(\"No outliers found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fd6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "Total audio duration:       16024.57 sec\n",
      "Total USV event duration:   142.87 sec\n",
      "Total non-USV duration:     15881.70 sec\n",
      "Non-USV is 111.2× USV duration\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "# 2. Time parser (as before)\n",
    "def parse_time_to_seconds(time_str: str) -> float:\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        hours = float(parts[0]); minutes = float(parts[1]); seconds = float(parts[2])\n",
    "    elif len(parts) == 2:\n",
    "        hours = 0.0; minutes = float(parts[0]); seconds = float(parts[1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "# 3. Paths\n",
    "root_dir = 'XXXX'\n",
    "csv_pattern = os.path.join(root_dir, '**', '*.csv')\n",
    "wav_pattern = os.path.join(root_dir, '**', '*.wav')\n",
    "\n",
    "csv_files = glob.glob(csv_pattern, recursive=True)\n",
    "wav_files = glob.glob(wav_pattern, recursive=True)\n",
    "\n",
    "\n",
    "# 4. Sum up USV durations from CSVs\n",
    "total_usv_time = 0.0\n",
    "for f in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, sep=r'[,\\t]+', engine='python', dtype=str)\n",
    "    except:\n",
    "        continue\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if 'Duration' not in df.columns:\n",
    "        continue\n",
    "    df = df.dropna(subset=['Duration'])\n",
    "    df = df[df['Duration'].str.strip() != '']\n",
    "    if df.empty:\n",
    "        continue\n",
    "    total_usv_time += df['Duration'].apply(parse_time_to_seconds).sum()\n",
    "\n",
    "# 5. Sum up total audio time from WAVs\n",
    "total_audio_time = 0.0\n",
    "for wav in wav_files:\n",
    "    try:\n",
    "        data, sr = sf.read(wav, dtype='float32')\n",
    "    except:\n",
    "        continue\n",
    "    duration = len(data) / sr\n",
    "    total_audio_time += duration\n",
    "\n",
    "# 6. Compute non-USV time and ratio\n",
    "total_no_usv_time = total_audio_time - total_usv_time\n",
    "ratio = total_no_usv_time / total_usv_time if total_usv_time > 0 else float('inf')\n",
    "\n",
    "# 7. Print results\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Total audio duration:       {total_audio_time:.2f} sec\")\n",
    "print(f\"Total USV event duration:   {total_usv_time:.2f} sec\")\n",
    "print(f\"Total non-USV duration:     {total_no_usv_time:.2f} sec\")\n",
    "print(f\"Non-USV is {ratio:.1f}× USV duration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d436fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to RatPup_dataset.csv\n",
      "type\n",
      "train    0.699974\n",
      "val      0.200017\n",
      "test     0.100009\n",
      "Name: proportion, dtype: float64\n",
      "usv\n",
      "0    0.745535\n",
      "1    0.254465\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "ROOT_DIR             = 'XXXX'\n",
    "USV_CSV_PATTERN      = ROOT_DIR + '/**/*.csv'\n",
    "WAV_PATTERN          = ROOT_DIR + '/**/*.wav'\n",
    "DATASET_CSV          = 'RatPup_dataset.csv'\n",
    "DATASET_NAME         = 'RatPup'\n",
    "\n",
    "WINDOW_LENGTH_SEC    = 0.220    # 220 ms windows\n",
    "STEP_SEC             = 0.110    # 50% overlap\n",
    "TRAIN_FRAC           = 0.70\n",
    "VAL_FRAC             = 0.20\n",
    "TEST_FRAC            = 0.10\n",
    "\n",
    "# Heuristic target class fractions\n",
    "ACTUAL_POS_FRAC      = 0.0089   # ≈ 0.89%\n",
    "ACTUAL_NEG_FRAC      = 0.9911   # ≈ 99.11%\n",
    "TARGET_POS_FRAC      = (ACTUAL_POS_FRAC + 0.50) / 2   # ≈ 25.44%\n",
    "TARGET_NEG_FRAC      = (ACTUAL_NEG_FRAC + 0.50) / 2   # ≈ 74.56%\n",
    "\n",
    "# For window-count–based negative sampling\n",
    "NEG_PER_POS          = TARGET_NEG_FRAC / TARGET_POS_FRAC\n",
    "\n",
    "RANDOM_SEED          = 42\n",
    "\n",
    "# 1. Imports\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# 2. Parse time string to seconds\n",
    "def parse_time_to_seconds(ts: str) -> float:\n",
    "    parts = ts.split(':')\n",
    "    if len(parts) == 3:\n",
    "        h, m, s = parts\n",
    "    elif len(parts) == 2:\n",
    "        h, m, s = '0', parts[0], parts[1]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected time format: {ts}\")\n",
    "    return float(h) * 3600 + float(m) * 60 + float(s)\n",
    "\n",
    "# 3. Load USV events and filter out outliers\n",
    "durations = []\n",
    "for csv_file in glob.glob(USV_CSV_PATTERN, recursive=True):\n",
    "    df = pd.read_csv(csv_file, sep=r'[,\\t]+', engine='python', dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if 'Duration' not in df.columns or 'Start' not in df.columns:\n",
    "        continue\n",
    "    df = df.dropna(subset=['Duration','Start'])\n",
    "    df = df[df['Duration'].str.strip()!='']\n",
    "    df['dur_sec']   = df['Duration'].apply(parse_time_to_seconds)\n",
    "    durations.extend(df['dur_sec'].tolist())\n",
    "\n",
    "q1 = pd.Series(durations).quantile(0.25)\n",
    "q3 = pd.Series(durations).quantile(0.75)\n",
    "upper_fence = q3 + 1.5*(q3 - q1)\n",
    "\n",
    "usv_events = {}\n",
    "for csv_file in glob.glob(USV_CSV_PATTERN, recursive=True):\n",
    "    df = pd.read_csv(csv_file, sep=r'[,\\t]+', engine='python', dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if 'Duration' not in df.columns or 'Start' not in df.columns:\n",
    "        continue\n",
    "    df = df.dropna(subset=['Duration','Start'])\n",
    "    df = df[df['Duration'].str.strip()!='']\n",
    "    df['dur_sec']   = df['Duration'].apply(parse_time_to_seconds)\n",
    "    df['start_sec'] = df['Start'].apply(parse_time_to_seconds)\n",
    "    df['end_sec']   = df['start_sec'] + df['dur_sec']\n",
    "    df = df[df['dur_sec'] <= upper_fence]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    wav_file = os.path.splitext(csv_file)[0] + '.wav'\n",
    "    usv_events[wav_file] = list(zip(df['start_sec'], df['end_sec']))\n",
    "\n",
    "# 4. Gather all WAV files\n",
    "all_wavs = glob.glob(WAV_PATTERN, recursive=True)\n",
    "\n",
    "# 5. Generate fixed-length windows and label\n",
    "rows = []\n",
    "for wav in all_wavs:\n",
    "    try:\n",
    "        data, sr = sf.read(wav, dtype='float32')\n",
    "    except:\n",
    "        continue\n",
    "    total_dur = len(data) / sr\n",
    "    events = usv_events.get(wav, [])\n",
    "    t = 0.0\n",
    "    while t + WINDOW_LENGTH_SEC <= total_dur:\n",
    "        start = t\n",
    "        end = t + WINDOW_LENGTH_SEC\n",
    "        is_pos = any(end > ev_start and start < ev_end for ev_start, ev_end in events)\n",
    "        rows.append({\n",
    "            'file_name': os.path.basename(wav),\n",
    "            'start'    : start,\n",
    "            'duration' : WINDOW_LENGTH_SEC,\n",
    "            'end'      : end,\n",
    "            'usv'      : int(is_pos),\n",
    "            'dataset'  : DATASET_NAME\n",
    "        })\n",
    "        t += STEP_SEC\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "pos_df = df[df['usv']==1]\n",
    "neg_df = df[df['usv']==0]\n",
    "\n",
    "# 6. Window-count–based negative sampling\n",
    "n_neg_needed = int(len(pos_df) * NEG_PER_POS)\n",
    "n_neg_needed = min(n_neg_needed, len(neg_df))  # in case of shortage\n",
    "neg_df = neg_df.sample(n=n_neg_needed, random_state=RANDOM_SEED)\n",
    "\n",
    "# 7. Combine and shuffle\n",
    "combined = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# 8. Split train/val/test with stratification\n",
    "train, temp = train_test_split(combined, train_size=TRAIN_FRAC, stratify=combined['usv'], random_state=RANDOM_SEED)\n",
    "val_size = VAL_FRAC / (VAL_FRAC + TEST_FRAC)\n",
    "val, test = train_test_split(temp, train_size=val_size, stratify=temp['usv'], random_state=RANDOM_SEED)\n",
    "\n",
    "for subset, name in [(train,'train'), (val,'val'), (test,'test')]:\n",
    "    subset['type'] = name\n",
    "\n",
    "# 9. Save dataset CSV\n",
    "dataset = pd.concat([train, val, test], ignore_index=True)\n",
    "dataset = dataset[['file_name','start','duration','end','usv','type','dataset']]\n",
    "dataset.to_csv(DATASET_CSV, index=False)\n",
    "\n",
    "print(f\"Dataset saved to {DATASET_CSV}\")\n",
    "print(dataset['type'].value_counts(normalize=True))\n",
    "print(dataset['usv'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27339e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff111699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91b364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07647eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd818c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc7609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15d0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6846fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e65e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cd269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-data-science-kernel-py311)",
   "language": "python",
   "name": "ml-data-science-kernel-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
