{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc89042",
   "metadata": {},
   "source": [
    "Construction of the NABat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00733d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Rate Distribution:\n",
      "  192000 Hz\n",
      "  250000 Hz\n",
      "  256000 Hz\n",
      "  300000 Hz\n",
      "  320000 Hz\n",
      "  384000 Hz\n",
      "  500000 Hz\n",
      "\n",
      "Duration Statistics (seconds):\n",
      "  Mean    : 4.4721\n",
      "  Median  : 4.9990\n",
      "  Std Dev : 2.2880\n",
      "  Q1      : 2.8940\n",
      "  Q3      : 5.0000\n",
      "  IQR     : 2.1060\n",
      "  Lower   : -0.2650\n",
      "  Upper   : 8.1590\n",
      "\n",
      "Outlier Durations:\n",
      "  Number of outliers: 92\n",
      "  Min outlier: 8.1800 sec\n",
      "  Max outlier: 15.0040 sec\n",
      "  First 10 outliers:\n",
      "    10.2760 sec\n",
      "    13.5433 sec\n",
      "    8.4300 sec\n",
      "    12.4980 sec\n",
      "    15.0000 sec\n",
      "    9.3960 sec\n",
      "    15.0000 sec\n",
      "    9.7860 sec\n",
      "    15.0000 sec\n",
      "    15.0000 sec\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# 2. Define positive and negative directories\n",
    "pos_dir = 'XXXX'   # Bat USV\n",
    "neg_dir = 'XXXX'    # Bat noise\n",
    "\n",
    "# 3. Collect all .wav files\n",
    "patterns = [\n",
    "    os.path.join(pos_dir, '**', '*.wav'),\n",
    "    os.path.join(neg_dir, '**', '*.wav')\n",
    "]\n",
    "file_paths = []\n",
    "for pattern in patterns:\n",
    "    file_paths.extend(glob.glob(pattern, recursive=True))\n",
    "\n",
    "# 4. Read samplerate and duration for each file\n",
    "durations = []\n",
    "samplerates = []\n",
    "\n",
    "for fp in file_paths:\n",
    "    try:\n",
    "        info = sf.info(fp)\n",
    "        sr = info.samplerate\n",
    "        duration = info.frames / sr\n",
    "        samplerates.append(sr)\n",
    "        durations.append(duration)\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {fp}: {e}')\n",
    "\n",
    "dur_arr = np.array(durations)\n",
    "sr_arr = np.array(samplerates)\n",
    "\n",
    "# 5. Print sampling rate distribution\n",
    "unique_srs, counts = np.unique(sr_arr, return_counts=True)\n",
    "print('Sampling Rate Distribution:')\n",
    "for sr, cnt in zip(unique_srs, counts):\n",
    "    print(f'  {sr} Hz')\n",
    "\n",
    "# 6. Compute duration statistics and IQR-based outliers\n",
    "mean_dur = dur_arr.mean()\n",
    "median_dur = np.median(dur_arr)\n",
    "std_dur = dur_arr.std()\n",
    "q1, q3 = np.percentile(dur_arr, [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_fence = q1 - 1.5 * iqr\n",
    "upper_fence = q3 + 1.5 * iqr\n",
    "outliers = dur_arr[(dur_arr < lower_fence) | (dur_arr > upper_fence)]\n",
    "\n",
    "print('\\nDuration Statistics (seconds):')\n",
    "print(f'  Mean    : {mean_dur:.4f}')\n",
    "print(f'  Median  : {median_dur:.4f}')\n",
    "print(f'  Std Dev : {std_dur:.4f}')\n",
    "print(f'  Q1      : {q1:.4f}')\n",
    "print(f'  Q3      : {q3:.4f}')\n",
    "print(f'  IQR     : {iqr:.4f}')\n",
    "print(f'  Lower   : {lower_fence:.4f}')\n",
    "print(f'  Upper   : {upper_fence:.4f}')\n",
    "\n",
    "print('\\nOutlier Durations:')\n",
    "print(f'  Number of outliers: {len(outliers)}')\n",
    "if len(outliers) > 0:\n",
    "    print(f'  Min outlier: {outliers.min():.4f} sec')\n",
    "    print(f'  Max outlier: {outliers.max():.4f} sec')\n",
    "    print('  First 10 outliers:')\n",
    "    for val in outliers[:10]:\n",
    "        print(f'    {val:.4f} sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fd6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration IQR: Q1=2.894, Q3=5.000, lower=-0.265, upper=8.159\n",
      "\n",
      "Sampling Rate Distribution (after resample):\n",
      "  250000 Hz\n",
      "\n",
      "Duration Statistics (seconds) after processing:\n",
      "  Mean  : 4.0527\n",
      "  Median: 4.9987\n",
      "  Std   : 1.4206\n",
      "  Q1    : 2.6320, Q3: 5.0000, IQR: 2.3680\n",
      "  Lower : -0.9200, Upper: 8.5520\n",
      "\n",
      "Remaining outliers: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# 2. Define source and target directories\n",
    "pos_dir = 'XXXX' # Bat USV\n",
    "neg_dir = 'XXXX' # Bat Noise\n",
    "output_dir = 'XXXX'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 3. Collect all WAV files\n",
    "patterns = [\n",
    "    os.path.join(pos_dir, '**', '*.wav'),\n",
    "    os.path.join(neg_dir, '**', '*.wav')\n",
    "]\n",
    "all_files = []\n",
    "for p in patterns:\n",
    "    all_files.extend(glob.glob(p, recursive=True))\n",
    "\n",
    "# 4. Compute durations for IQR-based outlier detection\n",
    "durations = []\n",
    "for fp in all_files:\n",
    "    info = sf.info(fp)\n",
    "    durations.append(info.frames / info.samplerate)\n",
    "dur_arr = np.array(durations)\n",
    "\n",
    "# 5. Compute IQR thresholds\n",
    "q1, q3 = np.percentile(dur_arr, [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_fence = q1 - 1.5 * iqr\n",
    "upper_fence = q3 + 1.5 * iqr\n",
    "print(f'Duration IQR: Q1={q1:.3f}, Q3={q3:.3f}, lower={lower_fence:.3f}, upper={upper_fence:.3f}')\n",
    "\n",
    "# 6. Process each file: skip outliers, resample, and save\n",
    "processed = 0\n",
    "skipped = 0\n",
    "\n",
    "for fp, dur in zip(all_files, dur_arr):\n",
    "    if dur < lower_fence or dur > upper_fence:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # load & resample to 250000 Hz\n",
    "    y, _ = librosa.load(fp, sr=250000)\n",
    "    out_fp = os.path.join(output_dir, os.path.basename(fp))\n",
    "    sf.write(out_fp, y, 250000)\n",
    "    processed += 1\n",
    "\n",
    "# 7. Final statistics on the output directory\n",
    "out_files = glob.glob(os.path.join(output_dir, '*.wav'))\n",
    "sr_list = []\n",
    "dur_list = []\n",
    "\n",
    "for fp in out_files:\n",
    "    info = sf.info(fp)\n",
    "    sr_list.append(info.samplerate)\n",
    "    dur_list.append(info.frames / info.samplerate)\n",
    "\n",
    "sr_arr = np.array(sr_list)\n",
    "dur_arr = np.array(dur_list)\n",
    "\n",
    "# 8. Print sampling rate distribution\n",
    "u_sr, cnt_sr = np.unique(sr_arr, return_counts=True)\n",
    "print('\\nSampling Rate Distribution (after resample):')\n",
    "for sr, cnt in zip(u_sr, cnt_sr):\n",
    "    print(f'  {sr} Hz')\n",
    "\n",
    "# 9. Print duration statistics and any remaining outliers\n",
    "mean_d = dur_arr.mean()\n",
    "med_d = np.median(dur_arr)\n",
    "std_d = dur_arr.std()\n",
    "q1_d, q3_d = np.percentile(dur_arr, [25, 75])\n",
    "iqr_d = q3_d - q1_d\n",
    "lf_d = q1_d - 1.5*iqr_d\n",
    "uf_d = q3_d + 1.5*iqr_d\n",
    "outliers_d = dur_arr[(dur_arr<lf_d)|(dur_arr>uf_d)]\n",
    "\n",
    "print('\\nDuration Statistics (seconds) after processing:')\n",
    "print(f'  Mean  : {mean_d:.4f}')\n",
    "print(f'  Median: {med_d:.4f}')\n",
    "print(f'  Std   : {std_d:.4f}')\n",
    "print(f'  Q1    : {q1_d:.4f}, Q3: {q3_d:.4f}, IQR: {iqr_d:.4f}')\n",
    "print(f'  Lower : {lf_d:.4f}, Upper: {uf_d:.4f}')\n",
    "\n",
    "print(f'\\nRemaining outliers: {len(outliers_d)}')\n",
    "if len(outliers_d)>0:\n",
    "    print(f'  Min: {outliers_d.min():.4f}, Max: {outliers_d.max():.4f}')\n",
    "    print('  Sample outlier durations:')\n",
    "    print(outliers_d[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f149e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary by Class ===\n",
      "Total bat USV audio duration:   4969.00 sec\n",
      "Total noise audio duration: 1486.87 sec\n",
      "Bat non-USV is 0.3× USV duration\n"
     ]
    }
   ],
   "source": [
    "# === Summary by Class (bat vs noise) ===\n",
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "\n",
    "# 1. Define the output directory\n",
    "output_dir = 'XXXX'\n",
    "\n",
    "# 2. Statistical positive and negative events\n",
    "bat_files   = glob.glob(os.path.join(output_dir, 'MYLU*.wav'))\n",
    "noise_files = glob.glob(os.path.join(output_dir, 'NOISE*.wav'))\n",
    "\n",
    "total_bat   = sum(sf.info(fp).frames / sf.info(fp).samplerate for fp in bat_files)\n",
    "total_noise = sum(sf.info(fp).frames / sf.info(fp).samplerate for fp in noise_files)\n",
    "total_audio = total_bat + total_noise\n",
    "\n",
    "ratio = total_noise / total_bat if total_bat > 0 else float('inf')\n",
    "\n",
    "# 3. Print outcome\n",
    "print(\"=== Summary by Class ===\")\n",
    "print(f\"Total bat USV audio duration:   {total_bat:.2f} sec\")\n",
    "print(f\"Total noise audio duration: {total_noise:.2f} sec\")\n",
    "print(f\"Bat non-USV is {ratio:.1f}× USV duration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479551c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window generation complete:\n",
      "usv\n",
      "1    43660\n",
      "0    12735\n",
      "Name: count, dtype: int64 windows (0=noise, 1=bat)\n",
      "Split proportions (train/val/test):\n",
      "type\n",
      "train    0.699991\n",
      "val      0.200000\n",
      "test     0.100009\n",
      "Name: proportion, dtype: float64\n",
      "Class balance (0=noise, 1=bat):\n",
      "usv\n",
      "1    0.774182\n",
      "0    0.225818\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "ROOT_DIR             = 'XXXX'\n",
    "WAV_PATTERN          = ROOT_DIR + '/**/*.wav'\n",
    "DATASET_CSV          = 'NABat_dateset.csv'\n",
    "DATASET_NAME         = 'NABat'\n",
    "\n",
    "WINDOW_LENGTH_SEC    = 0.220    # 220 ms windows\n",
    "STEP_SEC             = 0.110    # 50% overlap\n",
    "TRAIN_FRAC           = 0.70\n",
    "VAL_FRAC             = 0.20\n",
    "TEST_FRAC            = 0.10\n",
    "\n",
    "# Heuristic target class fractions (for sampling)\n",
    "ACTUAL_POS_FRAC      = 0.77   # ≈ 77% positive files\n",
    "ACTUAL_NEG_FRAC      = 0.23   # ≈ 23% negative files\n",
    "TARGET_POS_FRAC      = (ACTUAL_POS_FRAC + 0.50) / 2   # ≈ 63.5%\n",
    "TARGET_NEG_FRAC      = (ACTUAL_NEG_FRAC + 0.50) / 2   # ≈ 36.5%\n",
    "NEG_PER_POS          = TARGET_NEG_FRAC / TARGET_POS_FRAC\n",
    "\n",
    "RANDOM_SEED          = 42\n",
    "\n",
    "# === 1. Imports ===\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 2. Reproducibility ===\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# === 3. Gather all WAV files ===\n",
    "all_wavs = glob.glob(WAV_PATTERN, recursive=True)\n",
    "\n",
    "# === 4. Generate fixed-length windows and assign label by filename prefix ===\n",
    "rows = []\n",
    "for wav_path in all_wavs:\n",
    "    try:\n",
    "        data, sr = sf.read(wav_path, dtype='float32')\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {wav_path}: {e}\")\n",
    "        continue\n",
    "    total_dur = len(data) / sr\n",
    "    label = 1 if os.path.basename(wav_path).startswith('MYLU') else 0\n",
    "    t = 0.0\n",
    "    while t + WINDOW_LENGTH_SEC <= total_dur:\n",
    "        rows.append({\n",
    "            'file_name': os.path.basename(wav_path),\n",
    "            'start'    : t,\n",
    "            'duration' : WINDOW_LENGTH_SEC,\n",
    "            'end'      : t + WINDOW_LENGTH_SEC,\n",
    "            'usv'      : label,\n",
    "            'dataset'  : DATASET_NAME\n",
    "        })\n",
    "        t += STEP_SEC\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Window generation complete:\")\n",
    "print(df['usv'].value_counts(), \"windows (0=noise, 1=bat)\")\n",
    "\n",
    "# === 5. Window-count–based negative sampling ===\n",
    "pos_df = df[df['usv'] == 1]\n",
    "neg_df = df[df['usv'] == 0]\n",
    "\n",
    "n_neg_needed = int(len(pos_df) * NEG_PER_POS)\n",
    "n_neg_needed = min(n_neg_needed, len(neg_df))\n",
    "neg_df = neg_df.sample(n=n_neg_needed, random_state=RANDOM_SEED)\n",
    "\n",
    "# === 6. Combine and shuffle ===\n",
    "combined = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# === 7. Split train/val/test with stratification ===\n",
    "train_df, temp_df = train_test_split(\n",
    "    combined, train_size=TRAIN_FRAC,\n",
    "    stratify=combined['usv'], random_state=RANDOM_SEED\n",
    ")\n",
    "val_frac_adjusted = VAL_FRAC / (VAL_FRAC + TEST_FRAC)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, train_size=val_frac_adjusted,\n",
    "    stratify=temp_df['usv'], random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "for subset, name in [(train_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "    subset['type'] = name\n",
    "\n",
    "# === 8. Save dataset to CSV ===\n",
    "dataset = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "dataset = dataset[['file_name', 'start', 'duration', 'end', 'usv', 'type', 'dataset']]\n",
    "\n",
    "os.makedirs(os.path.dirname(DATASET_CSV), exist_ok=True)\n",
    "dataset.to_csv(DATASET_CSV, index=False)\n",
    "\n",
    "# === 9. Report ===\n",
    "print(\"Split proportions (train/val/test):\")\n",
    "print(dataset['type'].value_counts(normalize=True))\n",
    "print(\"Class balance (0=noise, 1=bat):\")\n",
    "print(dataset['usv'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27339e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff111699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91b364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07647eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd818c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc7609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15d0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6846fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e65e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cd269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-data-science-kernel-py311)",
   "language": "python",
   "name": "ml-data-science-kernel-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
