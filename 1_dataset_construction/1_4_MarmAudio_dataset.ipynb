{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a52040",
   "metadata": {},
   "outputs": [],
   "source": [
    "Construction of the MarmAudio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fd6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration IQR: Q1=0.850, Q3=1.350, lower=0.100, upper=2.100\n",
      "\n",
      "Skipped 27 outliers\n",
      "\n",
      "Sampling Rate Distribution (after resample):\n",
      "  250000 Hz\n",
      "\n",
      "Duration Statistics (seconds) after processing:\n",
      "  Mean  : 2.2228\n",
      "  Median: 2.0152\n",
      "  Std   : 1.2115\n",
      "  Q1    : 1.5500, Q3: 2.4417, IQR: 0.8917\n",
      "  Lower : 0.2125, Upper: 3.7792\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# 2. Define source and target directories\n",
    "pos_dir = 'XXXX' # Marmoset USV\n",
    "neg_dir = 'XXXX' # Marmoset Noise\n",
    "output_dir = 'XXXX'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 3. Collect all WAV files\n",
    "patterns = [\n",
    "    os.path.join(pos_dir, '**', '*.wav'),\n",
    "    os.path.join(neg_dir, '**', '*.wav')\n",
    "]\n",
    "all_files = []\n",
    "for p in patterns:\n",
    "    all_files.extend(glob.glob(p, recursive=True))\n",
    "\n",
    "# 4. Compute durations for IQR-based outlier detection\n",
    "durations = []\n",
    "for fp in all_files:\n",
    "    info = sf.info(fp)\n",
    "    durations.append(info.frames / info.samplerate)\n",
    "dur_arr = np.array(durations)\n",
    "\n",
    "# 5. Compute IQR thresholds\n",
    "q1, q3 = np.percentile(dur_arr, [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_fence = q1 - 1.5 * iqr\n",
    "upper_fence = q3 + 1.5 * iqr\n",
    "print(f'Duration IQR: Q1={q1:.3f}, Q3={q3:.3f}, lower={lower_fence:.3f}, upper={upper_fence:.3f}')\n",
    "\n",
    "# 6. Process each file: skip outliers, resample, and save\n",
    "processed = 0\n",
    "skipped = 0\n",
    "\n",
    "for fp, dur in zip(all_files, dur_arr):\n",
    "    if dur < lower_fence or dur > upper_fence:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # load & resample to 250000 Hz\n",
    "    y, _ = librosa.load(fp, sr=250000)\n",
    "    out_fp = os.path.join(output_dir, os.path.basename(fp))\n",
    "    sf.write(out_fp, y, 250000)\n",
    "    processed += 1\n",
    "\n",
    "print(f'\\nSkipped {skipped} outliers')\n",
    "\n",
    "# 7. Final statistics on the output directory\n",
    "out_files = glob.glob(os.path.join(output_dir, '*.wav'))\n",
    "sr_list = []\n",
    "dur_list = []\n",
    "\n",
    "for fp in out_files:\n",
    "    info = sf.info(fp)\n",
    "    sr_list.append(info.samplerate)\n",
    "    dur_list.append(info.frames / info.samplerate)\n",
    "\n",
    "sr_arr = np.array(sr_list)\n",
    "dur_arr = np.array(dur_list)\n",
    "\n",
    "# 8. Print sampling rate distribution\n",
    "u_sr, cnt_sr = np.unique(sr_arr, return_counts=True)\n",
    "print('\\nSampling Rate Distribution (after resample):')\n",
    "for sr, cnt in zip(u_sr, cnt_sr):\n",
    "    print(f'  {sr} Hz')\n",
    "\n",
    "# 9. Print duration statistics and any remaining outliers\n",
    "mean_d = dur_arr.mean()\n",
    "med_d = np.median(dur_arr)\n",
    "std_d = dur_arr.std()\n",
    "q1_d, q3_d = np.percentile(dur_arr, [25, 75])\n",
    "iqr_d = q3_d - q1_d\n",
    "lf_d = q1_d - 1.5*iqr_d\n",
    "uf_d = q3_d + 1.5*iqr_d\n",
    "outliers_d = dur_arr[(dur_arr<lf_d)|(dur_arr>uf_d)]\n",
    "\n",
    "print('\\nDuration Statistics (seconds) after processing:')\n",
    "print(f'  Mean  : {mean_d:.4f}')\n",
    "print(f'  Median: {med_d:.4f}')\n",
    "print(f'  Std   : {std_d:.4f}')\n",
    "print(f'  Q1    : {q1_d:.4f}, Q3: {q3_d:.4f}, IQR: {iqr_d:.4f}')\n",
    "print(f'  Lower : {lf_d:.4f}, Upper: {uf_d:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f149e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary by Class ===\n",
      "Total audio duration:                      5216.86 sec\n",
      "Total positive (USV) audio duration:       723.39 sec\n",
      "Total negative (noise) audio duration:     4493.47 sec\n",
      "Noise-to-positive duration ratio:          6.2×\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "\n",
    "# 1. Define directory\n",
    "audio_dir = 'XXXX'\n",
    "\n",
    "# 2. Collect all .wav files\n",
    "audio_files = glob.glob(os.path.join(audio_dir, '**', '*.wav'), recursive=True)\n",
    "\n",
    "# 3. Classify by filename: files starting with \"NOISE\" are negative, the rest are positive\n",
    "negative_files = [fp for fp in audio_files if os.path.basename(fp).startswith('NOISE')]\n",
    "positive_files = [fp for fp in audio_files if not os.path.basename(fp).startswith('NOISE')]\n",
    "\n",
    "# 4. Sum durations\n",
    "total_negative = sum(sf.info(fp).frames / sf.info(fp).samplerate for fp in negative_files)\n",
    "total_positive = sum(sf.info(fp).frames / sf.info(fp).samplerate for fp in positive_files)\n",
    "total_duration = total_positive + total_negative\n",
    "\n",
    "# 5. Compute ratio negative/positive\n",
    "ratio = total_negative / total_positive if total_positive > 0 else float('inf')\n",
    "\n",
    "# 6. Print summary\n",
    "print(\"=== Summary by Class ===\")\n",
    "print(f\"Total audio duration:                      {total_duration:.2f} sec\")\n",
    "print(f\"Total positive (USV) audio duration:       {total_positive:.2f} sec\")\n",
    "print(f\"Total negative (noise) audio duration:     {total_negative:.2f} sec\")\n",
    "print(f\"Noise-to-positive duration ratio:          {ratio:.1f}×\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479551c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window generation complete:\n",
      "usv\n",
      "0    38447\n",
      "1     5565\n",
      "Name: count, dtype: int64 windows (0=noise, 1=usv)\n",
      "Split proportions (train/val/test):\n",
      "type\n",
      "train    0.699971\n",
      "val      0.200000\n",
      "test     0.100029\n",
      "Name: proportion, dtype: float64\n",
      "Class balance (0=noise, 1=usv):\n",
      "usv\n",
      "0    0.680997\n",
      "1    0.319003\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "ROOT_DIR             = 'XXXX'\n",
    "WAV_PATTERN          = ROOT_DIR + '/**/*.wav'\n",
    "DATASET_CSV          = 'MarmAudio_dataset.csv'\n",
    "DATASET_NAME         = 'MarmAudio'\n",
    "\n",
    "WINDOW_LENGTH_SEC    = 0.220    # 220 ms windows\n",
    "STEP_SEC             = 0.110    # 50% overlap\n",
    "TRAIN_FRAC           = 0.70\n",
    "VAL_FRAC             = 0.20\n",
    "TEST_FRAC            = 0.10\n",
    "\n",
    "# Heuristic target class fractions (for sampling)\n",
    "ACTUAL_POS_FRAC      = 0.138   # ≈ 13.8% positive windows\n",
    "ACTUAL_NEG_FRAC      = 0.862   # ≈ 86.2% negative windows\n",
    "TARGET_POS_FRAC      = (ACTUAL_POS_FRAC + 0.50) / 2   # ≈ 31.9%\n",
    "TARGET_NEG_FRAC      = (ACTUAL_NEG_FRAC + 0.50) / 2   # ≈ 68.1%\n",
    "NEG_PER_POS          = TARGET_NEG_FRAC / TARGET_POS_FRAC\n",
    "\n",
    "RANDOM_SEED          = 42\n",
    "\n",
    "# === 1. Imports ===\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 2. Reproducibility ===\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# === 3. Gather all WAV files ===\n",
    "all_wavs = glob.glob(WAV_PATTERN, recursive=True)\n",
    "\n",
    "# === 4. Generate fixed-length windows and assign label by filename prefix ===\n",
    "rows = []\n",
    "for wav_path in all_wavs:\n",
    "    try:\n",
    "        data, sr = sf.read(wav_path, dtype='float32')\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {wav_path}: {e}\")\n",
    "        continue\n",
    "    total_dur = len(data) / sr\n",
    "\n",
    "    # Label: files starting with \"NOISE\" are negative (0), all others are positive (1)\n",
    "    basename = os.path.basename(wav_path)\n",
    "    label = 0 if basename.startswith('NOISE') else 1\n",
    "\n",
    "    t = 0.0\n",
    "    while t + WINDOW_LENGTH_SEC <= total_dur:\n",
    "        rows.append({\n",
    "            'file_name': basename,\n",
    "            'start'    : t,\n",
    "            'duration' : WINDOW_LENGTH_SEC,\n",
    "            'end'      : t + WINDOW_LENGTH_SEC,\n",
    "            'usv'      : label,\n",
    "            'dataset'  : DATASET_NAME\n",
    "        })\n",
    "        t += STEP_SEC\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Window generation complete:\")\n",
    "print(df['usv'].value_counts(), \"windows (0=noise, 1=usv)\")\n",
    "\n",
    "# === 5. Window-count–based negative sampling ===\n",
    "pos_df = df[df['usv'] == 1]\n",
    "neg_df = df[df['usv'] == 0]\n",
    "\n",
    "n_neg_needed = int(len(pos_df) * NEG_PER_POS)\n",
    "n_neg_needed = min(n_neg_needed, len(neg_df))\n",
    "neg_df = neg_df.sample(n=n_neg_needed, random_state=RANDOM_SEED)\n",
    "\n",
    "# === 6. Combine and shuffle ===\n",
    "combined = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# === 7. Split train/val/test with stratification ===\n",
    "train_df, temp_df = train_test_split(\n",
    "    combined, train_size=TRAIN_FRAC,\n",
    "    stratify=combined['usv'], random_state=RANDOM_SEED\n",
    ")\n",
    "val_frac_adjusted = VAL_FRAC / (VAL_FRAC + TEST_FRAC)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, train_size=val_frac_adjusted,\n",
    "    stratify=temp_df['usv'], random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "for subset, name in [(train_df, 'train'), (val_df, 'val'), (test_df, 'test')]:\n",
    "    subset['type'] = name\n",
    "\n",
    "# === 8. Save dataset to CSV ===\n",
    "dataset = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "dataset = dataset[['file_name', 'start', 'duration', 'end', 'usv', 'type', 'dataset']]\n",
    "\n",
    "os.makedirs(os.path.dirname(DATASET_CSV), exist_ok=True)\n",
    "dataset.to_csv(DATASET_CSV, index=False)\n",
    "\n",
    "# === 9. Report ===\n",
    "print(\"Split proportions (train/val/test):\")\n",
    "print(dataset['type'].value_counts(normalize=True))\n",
    "print(\"Class balance (0=noise, 1=usv):\")\n",
    "print(dataset['usv'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d0625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bf1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c4d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf87a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27339e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff111699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91b364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07647eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd818c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc7609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15d0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6846fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e65e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cd269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-data-science-kernel-py311)",
   "language": "python",
   "name": "ml-data-science-kernel-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
